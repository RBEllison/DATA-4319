---
title: "Perceptron Classification Algorithm"
subtitle : "Using Titanic Data"
author: 'Author : Rose Ellison'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(magrittr)
library(tidyverse)
library(dplyr)
library(sqldf)
library(caTools)
library(ggplot2)
library(gridExtra)
```

## The Intuition
The perceptron algorithm is a type of supervised learning of binary classifiers. The algorithm is a simple neural network, learning the weights for the input signals in order to draw a linear decision boundary. This distinguishes between two linearly seperable classes +1 and -1. The weighted sum of the input of the model is called the activation.

$$ Activation = Weights * Inputs + Bias $$

If the activation is above 0.0, the model will output 1.0; otherwise, it will output 0.0.

$$ 1: Activation > 0.0 $$
$$ 0: Activation <= 0.0 $$

## Exploring the Example Dataset
The dataset we will be using to implement the percpetron algorithm is the titanic dataset from the R base library. The two independent variable are age and fare price. 

### Preprocessing

```{r, echo = FALSE}
data <- read.csv('../../../_resources/data/titanic.csv')
data$survived <- ifelse(data$survived == 1, 1, -1)
x <- data[ , c(5, 9)]
y <- data[ , 2]
```


### Plot
```{r, echo = FALSE}
ggplot(data,aes(x = data[, 5], 
                y = data[, 9], 
                color = factor(data[ , 2]))) + 
  geom_point() +
  labs(x = "Age", 
       y = "Fare Price") + 
  ggtitle("Survived : Fare Price vs Age")


```
From the plot, we can see this data is linearly seperable. The perceptron algorithm classifier should give us the line of best fit that best seperates this data.


## R Code

R code implementation of the perceptron algorithm, without the use of built-in functions.


```{r algorithm}

sign <- function(weights, x)
{
  weights <- as.integer(weights)
  x_bar <- as.integer(c(1.0, x[1], x[2]))
  return(ifelse((t(weights) * x_bar) > 0, 1, -1))
}


perceptron_update_rule <- function(w, x, y)
{
  if (sign(w, x) != y)
  {
    w <- w + (y * as.integer(c(1.0, x[1], x[2])))
  }
  return(w)
}

perceptron <- function(x, y, epochs)
{
  w <- rnorm(3)
  counter <- 1
  for (i in 1:epochs)
  {
    for (j in 1:nrow(data))
    {
      w <- perceptron_update_rule(w, x[j, ], y[j])
    }
    counter <- counter + 1
  }
  
  return(w)
}

w <- perceptron(x, y, 50)
w

```



## Visualizing the Classifier

```{r plots}


```
